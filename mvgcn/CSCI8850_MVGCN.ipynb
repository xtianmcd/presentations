{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> CSCI8850 Advanced Biomedical Imaging Analysis </p>\n",
    "## <p style=\"text-align: center;\">Paper Presentation </p>\n",
    "### <p style=\"text-align: center;\"> Christian McDaniel </p>\n",
    "\n",
    "### Multi-View Graph Convolutional Network and Its Applications on Neuroimage Analysis for Parkinsonâ€™s Disease \n",
    "### Zhang, _et. al._\n",
    "### 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Presentation Roadmap: \n",
    "\n",
    "+ Parkinson's Disease\n",
    "+ Neuroimage Analysis\n",
    "    + Modalities\n",
    "    + Previous efforts\n",
    "    + PPMI Dataset\n",
    "+ Background ( The Emerging Field of Signal Processing on Graphs):\n",
    "    + Graph Theory\n",
    "    + Spectral Graph Theory\n",
    "        + graph Laplacian\n",
    "    + Signal Processing\n",
    "        + Fourier Transform\n",
    "        + Chebyshev Polynomial\n",
    "    + Graph Fourier Transform (GFT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Presentation Roadmap (cont): \n",
    "\n",
    "+ Proposed Framework and Experiment\n",
    "    + Multi-View Graph Convolutional Network (MVGCN)\n",
    "        + Graph Convolutional Network (GCN)\n",
    "        + Multi-View Pooling\n",
    "    + Pairwise Matching\n",
    "    + Relationship Prediction\n",
    "    + Experiment Settings\n",
    "    + Results\n",
    "    + Conclusions\n",
    "    \n",
    "<img src=\"mvgcn.png\" alt=\"mvgcn\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease\n",
    "\n",
    "+ One of the most prevalent neurodegenerative diseases\n",
    "    + 500,000+ Americans\n",
    "    + 14th highest cause of death in US\n",
    "    \n",
    "<img src=\"http://www.doctorraman.com/wp-content/uploads/2016/06/PDgraphic.jpg\" alt=\"PD\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Pathology\n",
    "\n",
    "+ Predominantly affects the dopaminergic neurons in the substantia nigra\n",
    "+ Highly progressive \n",
    "+ Highly heterogeneous - clinical manifestations vary on an individual basis \n",
    "\n",
    "_ | _\n",
    ":-----:|:-----:\n",
    "![](http://www.flagstaffbusinessnews.com/wp-content/uploads/2017/09/Brain-Russel.jpg) | ![](https://images.agoramedia.com/everydayhealth/gcms/Recognizing-the-Progression-of-Parkinsons-722x406.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Parkinson's Disease - Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Diagnosis\n",
    "## Diagnosis is largely clinically based:\n",
    "\n",
    " _ | _ \n",
    ":-------:|:------:\n",
    "                <p style=\"text-align: left;\">+ Clinical assessments<br><br><br><br><br>+ Motor Symptoms: <br><br> -- bradykinesia,<br> -- rigidity,<br> -- resting tremors,<br> -- speech abnormalities </p>| ![](http://scienceforlife.altervista.org/blog/wp-content/uploads/2013/01/Sintomi-del-Parkinson.jpg)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Diagnosis\n",
    "\n",
    "## + Diagnosis has traditionally involved a degree of subjectivity, and its distinction between similar diseases can be somewhat arbitrary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Research\n",
    "\n",
    "## + There has been much effort to develop more rigorous, qualitative diagnostic tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Research\n",
    "\n",
    "## Much of the research is done using: \n",
    "\n",
    "### <p style=\"text-align: center;\"> Clinical Data </p>\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQKf2YkmXWmzAFlnXsFoPEwj8gq90Tr8YI7DCZK4ixhwuMby8mS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Research\n",
    "\n",
    "## Much of the research is done using: \n",
    "\n",
    "### <p style=\"text-align: center;\">  Genetic and Molecular Data </p>\n",
    "\n",
    "<img src=\"http://sciencemission.com/data/attachment.php?id=2184\" alt=\"gene\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Research\n",
    "\n",
    "## Much of the research is done using: \n",
    "\n",
    "### <p style=\"text-align: center;\"> Accelerometer Data </p>\n",
    "\n",
    "_ | _\n",
    ":---:|:---:\n",
    "![](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/c4e583e9a51bbbd49df7c4709c5cd3307ded5905/3-Figure1-1.png)|![](https://www.researchgate.net/profile/Mark_Shapiro2/publication/233539714/figure/fig2/AS:203361442897932@1425496554913/Typical-examples-of-accelerometer-readings-for-Parkinsons-patients-and-healthy-subjects.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parkinson's Disease - Pathology\n",
    "\n",
    "+ Predominantly affects the dopaminergic neurons in the substantia nigra\n",
    "+ Highly progressive \n",
    "+ Highly heterogeneous - clinical manifestations vary on an individual basis \n",
    "\n",
    "_ | _\n",
    ":-----:|:-----:\n",
    "![](http://www.flagstaffbusinessnews.com/wp-content/uploads/2017/09/Brain-Russel.jpg) | ![](https://images.agoramedia.com/everydayhealth/gcms/Recognizing-the-Progression-of-Parkinsons-722x406.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neuroimaging analysis emerged as a promising tool to:\n",
    "\n",
    "+ Capture the structural/functional differences observed\n",
    "+ Capture the progressive changes in the disease over time\n",
    "+ Account for the individual differences across PD pt's\n",
    "\n",
    "![](https://content.iospress.com/media/jpd/2015/5-4/jpd-5-4-jpd150623/jpd-5-4-jpd150623-g003.jpg?width=755)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neuroimaging Review: \n",
    "\n",
    "<p style=\"text-align: center;\"> MRI </p> | <p style=\"text-align: center;\"> DTI </p>\n",
    ":---:|:---:\n",
    "![](https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs10548-017-0568-9/MediaObjects/10548_2017_568_Fig7_HTML.jpg) | <img src=\"http://imaging.onlinejacc.org/content/jimg/7/10/1039/F1.large.jpg?width=800&height=600&carousel=1\" alt=\"dti\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Previous Neuroimaging research successes for PD research:\n",
    "\n",
    "+ _Volumetric_ differences in the **substantia nigra**\n",
    "+ _Volumetric_ loss in **olfactory bulbs/tracts** in PD pt's, and increased loss over PD duration \n",
    "+ Decreased _FA_ in substantia nigra (DTI)\n",
    "+ greater _FA_ reductions in **caudal (vs. middle/rostral) regions** of the SN\n",
    "    + distinguished PD from controls with 100% sensitivity _and_ specificity \n",
    "    \n",
    "![](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/fcd813a544f8c650f40b194a108b6fc43c732bba/5-Figure1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prevailing computational methods for neuroimaging analysis: \n",
    "\n",
    "+ data-driven and hypothesis free\n",
    "+ Mostly linear, multilinear\n",
    "+ Drive network discovery and imaging genomics \n",
    "\n",
    "![](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/d468dc25c4618d1d6a4427c68426593bb935a692/2-Figure1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations: \n",
    "\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ Linear methods for non-linear data\n",
    "\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ Too dependent on choice of algorithm/ parameter settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# These limitations inspired the development of data driven methods..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# These limitations inspired the development of data driven methods...\n",
    "\n",
    "# <p style=\"text-align: right;\"> ... in need of large amounts of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> The emergence of a large-scale PD-related neuroimaging database: </p>\n",
    "\n",
    "## <p style=\"text-align: center;\"> The PPMI Dataset </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> The PPMI Dataset </p>\n",
    "\n",
    "+ Large-scale multinational dataset\n",
    "+ Imaging, biological sampling, clinical/behavioral assessment data\n",
    "\n",
    "![](https://www.michaeljfox.org/files/blog/PPMI-logo_4.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> The PPMI Dataset </p>\n",
    "\n",
    "_ | _\n",
    ":---:|:---:\n",
    "+ Thousands of image sets<br><br>+ Multiple modalities<br><br>+ \"Test-retest\" feature<br><br>+ Raw and processed images | <img src=\"http://www.ppmi-info.org/wp-content/uploads/2013/08/IDAviewer.jpg\" alt=\"ida\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now that we have our dataset... \n",
    "\n",
    "# <p style=\"text-align: right;\"> ... we can plug-n-chug into our favorite state-of-the-art DL architecture, right? </p>\n",
    "\n",
    "<img src=\"https://zdnet4.cbsistatic.com/hub/i/2018/04/13/36c52953-7ab9-4608-a848-71d1d538856e/2cad00bf6c3dc3ff21009836b989cda7/td-deep-learning.jpg\" alt=\"dl\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature representation: \n",
    "\n",
    "+ Biomedical imaging is often **not optical imaging**\n",
    "\n",
    "+ Instead, we are _recreating_ an image from signal transmitted through an object (X-ray, CT) or from signals receied _from_ the object (MRI, DTI) \n",
    "\n",
    "    + The signals received are quite **noisy and incomplete**\n",
    "\n",
    "    + Additionally, each image typically varies on a subject-to-subject basis \n",
    "\n",
    "![](https://med.stanford.edu/bmrgroup/education/mri-physics/_jcr_content/main/image.img.320.high.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature representation: \n",
    "## The case for graph convolutional networks:\n",
    "\n",
    "+ dice coefficient / IoU as loss function (used for image segmentation) is **not sufficient** for internal structure/function representation\n",
    "![](https://www.omicsonline.org/articles-images/JCSB-07-209-g003.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature representation: \n",
    "## The multi-view graph convolutional network:\n",
    "\n",
    "![](https://pbs.twimg.com/media/Dd_eNq_VQAA6prs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis: it would be nice to borrow from _signal processing_ techniques, which are used to dealing with such messy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis: it would be nice to borrow from _signal processing_ techniques, which are used to dealing with such messy data\n",
    "\n",
    "# Enter: Shuman, _et. al._ (2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> The Emerging Field of Signal Processing on Graphs\n",
    "##### <p style=\"text-align: center;\"> Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains\n",
    "#### <p style=\"text-align: center;\"> Shuman _et. al._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> The Emerging Field of Signal Processing on Graphs\n",
    "##### <p style=\"text-align: center;\"> Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains\n",
    "#### <p style=\"text-align: center;\"> Shuman _et. al._\n",
    "\n",
    "### The goal was devised to process a graph signal as if it were a discrete-time signal\n",
    "+ Both a signal on a graph with _N_ vertices and a classical discrete-time signal with _N_ vertices can be viewed as vectors in **R**^N\n",
    "+ So, noisy fMRI images can be approximated as signals on weighted graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining the graph:\n",
    "\n",
    "+ G = {V, E, W}\n",
    "    + one graph = one image\n",
    "    + V = the samples in each image, i.e., ROI's \n",
    "        + a **signal** is defined on each vertex \n",
    "    + E = e(i,j) exists if the ROI's are structurally/functionally connected\n",
    "        + Not all ROI's are connected, but we can separate G into its M ROI subgraphs and independently process the signals therein \n",
    "    + W = weights associated with each edge (distance/similarity metric)\n",
    " \n",
    "_ | _\n",
    ":---:|:---:\n",
    "<img src=\"https://cdn-images-1.medium.com/max/300/1*UX5MP7F7E17JeFAaUNEdlA.png\" alt=\"grpha\" width=\"200\"/> | <img src=\"https://www.frontiersin.org/files/Articles/1419/fnsys-04-00016/image_m/fnsys-04-00016-g002.jpg\" alt=\"grph\" width=\"200\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining the graph - The graph Laplacian\n",
    "\n",
    "_ | _ \n",
    ":---:|:---:\n",
    "<img src=\"https://www.frontiersin.org/files/Articles/1419/fnsys-04-00016/image_m/fnsys-04-00016-g002.jpg\" alt=\"grph\" width=\"400\"/> | <img src=\"https://slideplayer.com/slide/2346657/8/images/32/Laplacian+Matrix+L+%3D+D+-+A.jpgcdn.com/graphanalyticsandmachinelearning-160127184721/95/graph-analytic-and-machine-learning-8-638.jpg?cb=1453920541\" alt=\"lap\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spectral Graph Domain:\n",
    "### The graph Laplacian\n",
    "\n",
    "_ | _ \n",
    ":---:|:---:\n",
    "![](https://image.slidesharecdn.com/ams-04-22-17-main-170623131819/95/higherorder-graph-clustering-at-ams-spring-western-sectional-6-638.jpg?cb=1498223972) | ![](https://people.eecs.berkeley.edu/~demmel/cs267/lecture20/LaplacianMatrix.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spectral Graph Domain:\n",
    "### The graph Laplacian\n",
    "\n",
    "+ Matrix whose i,jth entry is: \n",
    "    + negative iff i and j are adjacent (connected)\n",
    "    + 0 if i dne j and not connected\n",
    "    + arbitrary if i=j (often the degree) \n",
    "+ Symmetric matrix: \n",
    "    + A = its transpose; \n",
    "    + A has a complete set of orthonormal eigenvectors with associated real, non-negative eigenvalues\n",
    "+ non-normalized graph Laplacian: **L** = **D**-**W**\n",
    "    + **L** = **U V U**^T\n",
    "        + **U** is the matrix of eigenvectors on a graph \n",
    "        + **V** is the diagonal matrix of eigenvalues\n",
    "    + optimizes an objective relative to the number of nodes in the graph\n",
    "+ normalized graph Laplacian: **L^** = **I** - **D**^(-1/2) **W** **D**^(-1/2)\n",
    "    + optimizes relative to the volume of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining the graph signal \n",
    "\n",
    "### The graph signal is defined as the eigenvectors associated with the graph Laplacian at each vertex \n",
    "\n",
    "# Review:\n",
    "\n",
    "### Eigenvectors as descriptors of a data-space:\n",
    "\n",
    "_ | _ \n",
    ":---:|:---:\n",
    " <img src=\"http://www.sosmath.com/diffeq/system/linear/eigenvalue/image08.gif\" alt=\"eig\" width=\"400\"/> | ![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS2f04RduBiHPtv4EyACIluEmtvHqObgN1yUOvWFik2J427lDe2tQ)\n",
    "\n",
    "### A signal is now a linear combination of parts\n",
    "### The Spectrum is the set of eigenvectors, their eigenvalues and their multiplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review: \n",
    "\n",
    "## Spectral Graph Theory\n",
    "\n",
    "![](https://media.springernature.com/full/nature-static/assets/v1/image-assets/srep34944-f1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining the graph signal \n",
    "\n",
    "### The graph signal is defined as the eigenvectors associated with the graph Laplacian at each vertex\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/lec15-graphlaplacianembedding-161108174529/95/lec15-graph-laplacian-embedding-36-638.jpg?cb=1478627165\" alt=\"sig\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Processing the Signal  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Signal Processing: \n",
    "\n",
    "## <p style=\"text-align: center;\">  Function Approximation </p>\n",
    "\n",
    "<img src=\"https://chrisjmccormick.files.wordpress.com/2015/08/2d-function-approximation-example-with-gaussians.png\" alt=\"fnxn_approx\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Signal Processing: \n",
    "\n",
    "## <p style=\"text-align: center;\"> The Fourier Transform </p>\n",
    "\n",
    "<img src=\"http://mriquestions.com/uploads/3/4/5/7/34572113/3311485_orig.gif\" alt=\"FT\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fourier Series --> linearly separable components | Fourier space = Complex space\n",
    ":---:|:---:\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Euler%27s_formula_%28ita%29.svg/2000px-Euler%27s_formula_%28ita%29.svg.png\" alt=\"circle\" width=\"400\"/> | ![](https://i.stack.imgur.com/54mXa.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR5ldC69Kj4SVecO2S5hExwzlUjpzFcWqQdpSETjBk1Ylky58LG)\n",
    "\n",
    "![](http://www.videos.drphilclark.com/lessons/MAT230/Chapter_10/fourier/fourier_coeff.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Connecting the Laplacian to the Fourier Transform\n",
    "\n",
    "+ Fourier Transform: \n",
    "    + Expansion of a function in terms of the complex exponentials (i.e., cos(e) + _i_ sin(e)) \n",
    "    + offers a discretized function for the flux of a system\n",
    "+ Laplace Operator (1-D):\n",
    "    + The divergence of the gradient of a function (scalar notion of the gradient's flux)\n",
    "    + Those same complex exponentials are the eigenfunctions of the one-dimensional Laplace operator \n",
    "    + The eigenvalues 2(pi) * f * (t) carry a notion of _frequency_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Connecting the Laplacian to the Fourier Transform\n",
    "\n",
    "+ The graph FT can be defined on the vertices of G as the expansion of any function (signal) _f_ in terms of the eigenvectors of the graph Laplacian\n",
    "    + **L** = **U Î› U**^T\n",
    "    + Let x be the signal defined on the vertices of the graph\n",
    "        + The Graph Fourier Transform (GFT) is defined as x^ = **U**^T * x\n",
    "        + This converts the signal x to the spectral domain spanned by the Fourier basis **U**\n",
    "\n",
    "+ Magnitude of the eigenvalue is proportional to the frequency\n",
    "    + Eigenvectors associated with larger eigenvalues oscillate more rapidly between connected vertices \n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTalsU8bQA3i0VsTiR3oG_2ABW9EoJ9TEsSiDQQ_oEjJrAVwgagfQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fourier series best approximate continuous periodic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fourier series best approximate continuous periodic functions\n",
    "\n",
    "# And our functions are discrete, in limited space, and irregularly spaced "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's simplify further ... \n",
    "\n",
    "## <p style=\"text-align: center;\"> Chebyshev Polynomial </p>\n",
    "\n",
    "![](https://i.stack.imgur.com/1yGlm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <p style=\"text-align: center;\"> Chebyshev Polynomial </p>\n",
    "\n",
    "<img src=\"https://slideplayer.com/slide/6152165/18/images/20/Chebyshev+polynomials+-+interpolation.jpg\" alt=\"cheb\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <p style=\"text-align: center;\"> Chebyshev Polynomial </p>\n",
    "\n",
    "#### <p style=\"text-align: center;\"> The coefficients c(k) _are_ the Fourier coefficients a(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# THUS, ... \n",
    "\n",
    "## ... if we can learn the Chebyshev coefficients associated with the GFT of each image's signal ...\n",
    "\n",
    "## ... (comprised of the Laplacian eigenvectors across connected ROI's), ... \n",
    "\n",
    "## ... this can govern the convolutional operator of our CNN.\n",
    "\n",
    "### i.e., the Graph Convolutional Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now let's apply this to neuroimaging analysis for PD: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Current Paper:\n",
    "<p style=\"text-align: left;\"> Three Main Components </p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | _\n",
    ":---:|:---:\n",
    "<p style=\"text-align: left;\"> MV-GCN:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Incorporate multiple modalities<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to learn a feature representation <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;containing global and local information. <br><br>Similarity Measure:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Use this abstract feature representation<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to learn a similarity vector <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for a given pair of images <br><br> Softmax Classifier:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;so as to cluster similar images</p> | ![](mvgcn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature representation: \n",
    "## The multi-view graph convolutional network:\n",
    "\n",
    "![](https://pbs.twimg.com/media/Dd_eNq_VQAA6prs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now let's apply this to neuroimaging analysis for PD: \n",
    "\n",
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graph Construction:\n",
    "\n",
    "+ determine ROI's across all **MRI** images\n",
    "+ each ROI becomes a vertex on the **Brain Geometry Graph** (BGG)\n",
    "\n",
    "#### Global Information\n",
    "\n",
    "<img src=\"http://www.jneurosci.org/content/jneuro/36/30/7865/F1.large.jpg\" alt=\"BGG\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graph Construction:\n",
    "\n",
    "+ determine ROI's across all **MRI** images\n",
    "+ each ROI becomes a vertex on the **Brain Geometry Graph** (BGG)\n",
    "    + K-Nearest Neighbor graph\n",
    "    + edges are weighted by Gaussian similarity function of Euclidean distances\n",
    "    ![](http://4.bp.blogspot.com/-XUpO4krKh9g/U2K36psWDBI/AAAAAAAAAyI/pGPZTMlBo7g/s1600/Screen+Shot+2014-05-01+at+5.08.44+PM.png)\n",
    "    + This yields an adjecency matrix **A** representing the similarity to nearest similar ROIs\n",
    "+ All subjects share the same BGG\n",
    "+ We can define a shared graph Laplacian **L** on this map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Define the feature space: \n",
    "\n",
    "+ Use multiple brain tractography algorithms on **DTI** images to yield multiple **Brainn Connectivity Graphs** (BCGs)\n",
    "![](https://journals.plos.org/plosone/article/figure/image?size=inline&id=10.1371/journal.pone.0071229.g001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Define the feature space: \n",
    "\n",
    "+ Use multiple brain tractography algorithms on **DTI** images to yield multiple **Brainn Connectivity Graphs** (BCGs)\n",
    "    + V again equals the ROI's of the image \n",
    "    + E consists of the _connectivity strength_ between each ROI \n",
    "    + again yielding a similarity matrix **X**\n",
    "+ Each of _N_ image sets is associated with _M_ BCG's\n",
    "    + V is the same across BCG's, while E varies for each one\n",
    "    + Each subject is represented by a _group of similarity matrices_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relationship Prediction - Graph Convolutional Networks\n",
    "\n",
    "<img src=\"https://www.frontiersin.org/files/Articles/103659/fnhum-08-00653-HTML/image_m/fnhum-08-00653-g002.jpg\" alt=\"pipeline\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relationship Prediction - Graph Convolutional Networks\n",
    "\n",
    "+ Learn a feature matrix from each BCG and their shared BGG\n",
    "    + Each BCG can be represented by a **vector of Chebyshev coefficients**\n",
    "    + This captures the **local** traits of each individual and the **global** traits of the population\n",
    "+ Aggregate the feature matrices of a given image set via element-wise _view pooling_\n",
    "+ Train a final softmax classifier on the binary relationship between each _acquisition pair_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graph Convolutional Network\n",
    "\n",
    "+ Conveniently, convolutions in the vertex domain become multiplication operations in the graph spectral domain \n",
    "+ Remembering our equations for the graph Laplacian: **L** = **U Î› U**^T\n",
    "+ and the GFT: x^ = **U**^T * x\n",
    "+ we can define the graph convolution as such:\n",
    "    <img src=\"GCN.png\" alt=\"form\" width=\"400\"/>\n",
    "    + where Î¸ is a vector of Fourier coefficients\n",
    "    + g(Î¸) is the filter, a function of Î› such that, taking from our Chebyshev equation\n",
    "    ![](Chebyshev.png)\n",
    "    we can define ![](graph_conv.png)\n",
    "        + where Î¸(p) is a vector of Chebyshev coefficients \n",
    "        + T(Î› Ìƒ) is the Chebyshev polynomial of order p evaluated at Î› Ìƒ = 2Î›/Î»(max) - **I** (diag. matrix of scaled eigenvalues) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graph Convolutional Network\n",
    "\n",
    "## This substitution yields: \n",
    "\n",
    "![](GCN2.png)\n",
    "![](L~.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graph Convolutional Network\n",
    "\n",
    "## Further: \n",
    "\n",
    "+ If we define <img src=\"xp.png\" alt=\"xp\" width=\"100\"/>\n",
    "+ we see that <img src=\"recursive_xp.png\" alt=\"rec_xp\" width=\"300\"/>\n",
    "\n",
    "+ i.e., <img src=\"xp.png\" alt=\"xp\" width=\"100\"/> can be defined recursively from the normalized graph Laplacian and only the coefficients need to be learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graph Convolutional Network\n",
    "\n",
    "+ the jth output feature map from a GCN is given by ![](output.png)\n",
    "    + where x(i) is the i-th row of the input connectivity matrix (BCG) **X**\n",
    "        + there are _n_ rows in **X** corresponding to _n_ ROI's \n",
    "    + yielding F(in) x F(out) vectors of trainable Chebyshev coefficients \n",
    "+ each subject has a GCN output of M feature matrices \n",
    "    + one feature matrix per BCG (tractography view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# View pooling: \n",
    "\n",
    "+ Multiple tractographies are aggregated together \n",
    "+ An element-wise maximum operation is used across all M feature matrices for a given subject\n",
    "    + maximum operation combines the views' more informative features \n",
    "        + instead of averaging (weakening the strongest features) \n",
    "+ This produces a shared feature matrix **Z** for each subject\n",
    "    + giving a combined vector of Chebyshev coefficients for each ROI\n",
    "    \n",
    "![](https://pbs.twimg.com/media/Dd_eNq_VQAA6prs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pairwise Matching Strategy \n",
    "\n",
    "1. Compile the dataset of all pairs of feature matrices (**Z**)\n",
    "    + Normalize each matrix so that the sum of squares of each row = 1\n",
    "2. Define a pairwise Similarity measure: \n",
    "    + if two subjects are similar (re: PD v. HC)\n",
    "        + they should have a high probability of having the same class label \n",
    "    + ![](sim_meas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relationship Prediction\n",
    "\n",
    "+ The pairwise matching layer yields a feature vector **r** \n",
    "    + each element in **r** is a row-wise similarity \n",
    "+ **r** is passed to a fully-connected Softmax layer for classification \n",
    "    + ![](softmax.png)\n",
    "    + where w(c) is the weight vector of the _c_-th class and **r** is the final abstract representation of the input example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# IN SUMMARY:\n",
    "\n",
    "+ This network has three main components: \n",
    "    + Multi-View Graph Convolutional Network (MVGCN)\n",
    "        + Learn a feature representation for each subject across multiple BCG's (tractography views) \n",
    "            + Features obtained via the normalized graph Laplacian matrix and the graph Fourier Transform \n",
    "    + Pairwise Matching Strategy \n",
    "    + Softmax Relationship Prediction \n",
    "+ Each component is trained using backpropogation and stochastic optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Data: DTI\n",
    "\n",
    "+ DTI acquisitions of 754 subjects (PPMI)\n",
    "    + 596 PD\n",
    "    + 158 HC\n",
    "+ Head Motion and eddy-current distortion correction: \n",
    "    + FSL eddy-correct tool\n",
    "+ Skull-stripping/ brain segmentation:\n",
    "    + FSL Brain Extraction Tool (BET) \n",
    "+ echo-planar induced (EPI) susceptibility artifacts (e.g., tissue-fluid interface distortions)\n",
    "    + co-registred to respective preprocessed structural MRI images\n",
    "    + Advanced Normalization Tools (ANT) with SyN non-linear registration algorithm \n",
    "\n",
    "_ | _ | _\n",
    ":---:|:---:|:---:\n",
    "![](https://www.michaeljfox.org/files/blog/PPMI-logo_4.jpg) | ![](https://www.abbreviations.com/images/1535419_FMRIB%20Software%20Library.png) | <img src=\"https://biii.eu/sites/default/files/2018-01/ants_logo.png\" alt=\"ATNs\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Data: MRI\n",
    "\n",
    "+ 84 ROIs are parcellated from T1-weighted structural MRI using Freesurfer\n",
    "    + **BGG**: Each ROI's corrdinate is defined using the mean coordinate for all voxels\n",
    "    \n",
    "<img src=\"https://i.ytimg.com/vi/6wxJ1up-E7E/maxresdefault.jpg\" alt=\"mri\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BCGs: Tractography algorithms\n",
    "\n",
    "## Based on the 84 ROIs in the BGG,\n",
    "\n",
    "## 6 BCGs are constructed for each subject\n",
    "+ Four tensor-based deterministic approaches:\n",
    "    + Fiber Assignment by Continuous Tracking (FACT)\n",
    "    + 2nd-order Runge-Kutta (RK2)\n",
    "    + Interpolation streamline (SL)\n",
    "    + Tensorline (TL)\n",
    "+ One orientation distribution function (ODF)-based deterministic approach:\n",
    "    + ODF-RK2\n",
    "+ One ODF-based probabilistic approach\n",
    "    + Hugh voting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating the pairwise dataset: \n",
    "\n",
    "+ 283,881 pairs in total (matching v. non-matching brain networks) \n",
    "    + PD - PD pair is a match\n",
    "    + HC - HC pair is a match\n",
    "    + PD - HC pair is a non-match\n",
    "    + 189,713 matching pairs\n",
    "    + 94, 168 non-matching pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiment Settings:\n",
    "\n",
    "+ 5-fold stratified CV \n",
    "+ BGG: 10-NN BGG is constructed\n",
    "    + 84 vertices, 527 edges \n",
    "+ For fully connected layers:\n",
    "    + Tested one-layer: 1024 units\n",
    "    + and 2 layer: 1024 units - 64 units\n",
    "+ Adam optimizer with initial learning rate = 0.005 \n",
    "+ Architecture settings were optimized via CV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results (1): GCN\n",
    "\n",
    "+ Compared GCN to raw-edges weights and PCA performance for each DTI tractography algorithm\n",
    "+ Used same matching component and softmax component for each method \n",
    "\n",
    "![](Results1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results (2): MVGCN\n",
    "\n",
    "+ Compared the clustering abilities of the MVGCN (re: PD vs. HC) \n",
    "    + Clustering performance measured via Normalized Mutual Information (NMI)\n",
    " ![](Results2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results (3): Visualization - Binary Similarity\n",
    "\n",
    "+ used the relationship prediction generated from the various models to map all 754 DTI acquisitions distanced by their predicted similarity \n",
    "\n",
    "![](viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results (4): Visualisation - ROI Similarity\n",
    "\n",
    "+ The MVGCN output consists of ROI-wise pairwise similarity \n",
    "+ Able to visualize the 10 most similar or dissimilar ROIs for PD vs. HC\n",
    "<img src=\"vizROI.png\" alt=\"vizROI\" width=\"400\"/>\n",
    "+ Key Findings: \n",
    "    + Lateral orbitofrontal area, middle temporal and amygdala are three most similar ROIs for PD\n",
    "    + Caudate and putamen are discriminative b/t Pd and HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discussion/ Conclusions: \n",
    "\n",
    "+ MVGCN allows modeling multiple brain connectivity networks (BCGs) and brain geometry graphs (BGG) based on common ROIs and tractography algorithms \n",
    "    + BCGs are non-Euclidean, so standard convolution is not straightforward to use and must be specifically defined\n",
    "+ Multi-view approach allows the exploration of various aspects of the data \n",
    "+ Pairwise method increases the size of the dataset \n",
    "+ Straightforward interpretations of the networks were learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
