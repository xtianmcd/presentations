{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Emory University - Fall '18\n",
    "## <p style=\"text-align: center;\"> Christian McDaniel\n",
    "\n",
    "## Developing a Start-to-Finish Pipeline for Accelerometer-Based Activity Recognition Using Long Short-Term Memory Recurrent Neural Networks \n",
    "### Christian McDaniel and Shannon Quinn \n",
    "#### _SciPy 2018 Conference Proceedings_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Presentation Roadmap: \n",
    "\n",
    "1. Background - Title Breakdown <br>\n",
    "    1. Accelerometer-Based Activity Recognition\n",
    "        + What\n",
    "        + Why\n",
    "        + How\n",
    "    2. Using Long Short-Term Memory Recurrent Neural Networks\n",
    "        + What\n",
    "        + Why\n",
    "        + How\n",
    "    3. Developing a Start-to-Finish Pipeline\n",
    "2. Related Works - A Glimpse at the Field\n",
    "3. Methods\n",
    "4. Results, Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Developing a Start-to-Finish Pipeline for Accelerometer-Based Activity Recognition Using Long Short-Term Memory Recurrent Neural Networks </p>\n",
    "\n",
    "\n",
    "## <p style=\"text-align: center;\"> Christian McDaniel and Shannon Quinn </p>\n",
    "### <p style=\"text-align: center;\"> SciPy 2018 Conference Proceedings </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### That's a loot of words... lets break it down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Accelerometer-Based Activity Recognition\" </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Accelerometer-Based Activity Recognition\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) The \"What\"\n",
    "\n",
    " | | \n",
    ":-----------------------:|:---------------:|:-------------------------:\n",
    "<img src=\"http://blog.cityzendata.com/img/accelerometer_jogging.jpg\" alt=\"drawing\" width=\"400\" height=\"400\" /> |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| ![](https://usercontent2.hubstatic.com/3537899.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Accelerometer-Based Activity Recognition\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"Why\"\n",
    "\n",
    " | | \n",
    ":-----------------------:|:---------------:|:-------------------------:\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRRJSltMdRbtiwHkdbhOHrVqzmfEz8f17oVf2g4J0vdesTxgn7A) | <p style=\"text-align: left;\"> From Human Health (HAR).... </p> <br> <br>To Machine Health (LOL) | <img src=\"http://www.machinehealth.com/images/Coloured_gear_rot.gif\" alt=\"drawing\" width=\"200\" height=\"1000\"/> <img src=\"http://craziestgadgets.com/wp-content/uploads/2011/11/dancing-robot-650x650.jpg\" alt=\"drawing\" width=\"200\" height=\"200\"/>\n",
    "<p style=\"text-align: center;\"> 1998 </p> | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <p style=\"text-align: center;\"> 2018 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Accelerometer-Based Activity Recognition\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"Why\"\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Activities of Daily Life (ADL):\n",
    "\n",
    "&nbsp; | &nbsp; \n",
    ":-----------------------:|:---------------:\n",
    "![](https://media.springernature.com/lw785/springer-static/image/art%3A10.1186%2Fs12984-017-0331-1/MediaObjects/12984_2017_331_Fig1_HTML.gif) | ![](https://camo.githubusercontent.com/531a4566783d327ae3ff4312e3d2f72073fa85e8/687474703a2f2f692e696d6775722e636f6d2f584d594b7753342e706e67)| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Accelerometer-Based Activity Recognition\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"Why\"\n",
    "\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Clinical Diagnosis: \n",
    "<p style=\"text-align: center;\"> Parkinson's Disease (Motor SXs) </p>| <p style=\"text-align: center;\"> Nighttime Scratching </p>\n",
    ":-----------------------:|:---------------:\n",
    "![](https://www.frontiersin.org/files/Articles/27698/fneur-03-00158-HTML/image_m/fneur-03-00158-g002.jpg) | ![](https://www.nestleskinhealth.com/sites/g/files/jcdfhc196/files/inline-images/ItchTracker_for%20Media%20Eng_170411-2.png) | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Accelerometer-Based Activity Recognition\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"Why\"\n",
    "\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fill in the Blank:\n",
    "<p style=\"text-align: center;\"> XCS </p> | Driver Training and Industry Training | <p style=\"text-align: center;\"> ASL </p> \n",
    ":-----------------------:|:---------------:|:--------------:\n",
    "<img src=\"http://www.mdpi.com/sensors/sensors-12-05047/article_deploy/html/images/sensors-12-05047-ag.jpg\" alt=\"drawing\" width=\"300\" height=\"200\"/> | <img src=\"https://newsroom.aaa.com/wp-content/uploads/2015/03/Teens-Crash-Causation.jpg\" alt=\"drawing\" width=\"200\" height=\"200\"/> | <img src=\"https://c.slashgear.com/wp-content/uploads/2016/11/b_gesture_set.jpg\" alt=\"drawing\" width=\"400\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Accelerometer-Based Activity Recognition\" </p>\n",
    "###  3) The \"How\"\n",
    "\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Key Points:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; >  Classical vs. AI \n",
    "    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; >  Online/ On-Device vs. _post hoc_ analysis\n",
    "\n",
    "![](http://www.nickgillian.com/archive/wiki/grt/tutorials/GettingStarted/GestureRecognitionPipelineImage_01.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"text-align: center;\"> ... which brings us to ... </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) The \"What\" - **Artificial Neural Networks** <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) The \"What\" - Artificial Neural Networks\n",
    "<img src=\"ANN.png\" alt=\"ANN\" width=\"600\" height=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# General Training Pipeline: \n",
    "\n",
    "1. Conduct a forward pass, \n",
    "    + compute y ̃ and compare with y to generate the error term\n",
    "2. Backpropagate the error regarding the correction needed for y ̃\n",
    "3. Backpropagate the correction to the hidden layer\n",
    "4. update weight matrices A and B via dy and dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://iamwilchung.files.wordpress.com/2007/03/animate_ann.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://ruder.io/content/images/2016/09/saddle_point_evaluation_optimizers.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Bias - Variance Tradeoff </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Bias - Variance Tradeoff </p>\n",
    "## <p style=\"text-align: center;\"> These networks are very flexible! </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Bias - Variance Tradeoff </p>\n",
    "## <p style=\"text-align: center;\"> These networks are very flexible! </p>\n",
    "### <p style=\"text-align: center;\"> And very capable of overfitting the data <p>\n",
    "\n",
    "_ | _\n",
    ":--:|:--:\n",
    "![](https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/ds/overfitting.png) | ![](https://cdn-images-1.medium.com/max/771/1*cdvfzvpkJkUudDEryFtCnA.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Bias - Variance Tradeoff </p>\n",
    "## <p style=\"text-align: center;\"> These networks are very flexible! </p>\n",
    "### <p style=\"text-align: center;\"> And very capable of overfitting the data <p>\n",
    "### <p style=\"text-align: center;\"> Not to mention, going deeper has led to issues (i.e., exploding and vanishing gradients)\n",
    "<img src=\"https://steemitimages.com/0x0/https://c10.patreonusercontent.com/3/eyJ3Ijo2MjB9/patreon-posts/VH9flw-XerdL4CUriy8k-GA82OLetHQGdlxWyVQn7B_aUUuxKITBbOT0EEpFAYPB.gif?token-time=1523145600&token-hash=uK8713p8Mheye1yoiqHhMykjao5VfQAQwZvKyOWxw5g%3D\" alt=\"exploding gradients\" width=\"400\" height=\"400\"/>\n",
    "+ e.g., the magnitude of the update gets smaller as the error gradient is backpropagated to shallower layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some methods to help with this: \n",
    " + `Early Stopping` &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; `Weight Decay` &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; `Dropout` &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; `Learning Rate` &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; `Norm Regularization` &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; `Gradient Clipping` &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; `Batch Normalization`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# And there's the issue of having _time series_ data\n",
    "\n",
    "<p style=\"text-align: center;\"> This data </p> | | <p style=\"text-align: center;\"> This data </p>\n",
    ":---------:|:-----:|:------:\n",
    "<img src=\"https://1.cms.s81c.com/sites/default/files/styles/product_offering_image/public/2018-03/DataRefinery.png?itok=CAmEHVGX\" alt=\"data\" width=\"400\"/> | ... Is a bit different than ... | <img src=\"http://aqibsaeed.github.io/img/har-activity-standing.png\" alt=\"tsdata\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) The \"What\" - **Recurrent Neural Networks** <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) The \"What\" - Recurrent Neural Networks\n",
    "\n",
    "<p style=\"text-align: center;\"> <img src=\"RNN.png\" alt=\"RNN\" width=\"400\" height=\"400\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Each neuron now has TWO sets of weights: \n",
    "#### <p style=\"text-align: center;\"> y(t) = φ(Wx ·x(t) +Wy ·Y(t−1) +b) </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation is performed on the \"unrolled\" neuron, \n",
    "#### i.e., **\"Back Propagation Through Time\" (BPTT)**\n",
    "\n",
    "<p style=\"text-align: center;\"> <img src=\"RNN.png\" alt=\"RNN\" width=\"400\" height=\"400\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation is performed on the \"_unrolled_\" neuron, i.e., **\"Back Propagation Through Time\" (BPTT)**\n",
    "\n",
    "### This causes the networks to become _very_ deep _very_ quickly \n",
    "#### <p style=\"text-align: center;\"> depth = n timesteps per input per layer </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Re-enter: Exploding and Vanishing Gradients\n",
    "\n",
    "+ As the gradient is back-propagated, its influence on the weight matrix at a given layer decreases \"through time\"\n",
    "\n",
    "![](https://steemitimages.com/0x0/https://c10.patreonusercontent.com/3/eyJ3Ijo2MjB9/patreon-posts/VH9flw-XerdL4CUriy8k-GA82OLetHQGdlxWyVQn7B_aUUuxKITBbOT0EEpFAYPB.gif?token-time=1523145600&token-hash=uK8713p8Mheye1yoiqHhMykjao5VfQAQwZvKyOWxw5g%3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) The \"What\" - **The Long Short-Term Memory Cell** <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) The \"What\" - The Long Short-Term Memory Cell\n",
    "\n",
    "<img src=\"LSTMcell.pdf\" alt=\"LSTM\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "**Inputs:** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`x(t)` = single time-step fed into 4 independent fully-connected layers &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`h(t)` = short-term state &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`c(t)` = long-term state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Four gates (each with its own _pair_ of sets of weights):\n",
    "<p style=\"text-align: center;\"> `i(t)` = σ(W)xi·x(t) +Whi ·h(t−1) +bi <br><br>\n",
    "`f(t)` =σ(W)xf·x(t)+Whf ·h(t−1)+bf <br><br>\n",
    "`o(t)` = σ(W)xo·x(t) +Who ·h(t−1) +bo <br><br>\n",
    "**`g(t)`** = σ(W)xg·x(t) +Whg ·h(t−1) +bg<br><br> </p>\n",
    "\n",
    "## And two state vectors:\n",
    "<p style=\"text-align: center;\"> `c(t)` = f(t) ⊗ c(t−1) + i(t) ⊗ g(t) <br><br>\n",
    "`y(t)` = h(t) = o(t) ⊗ tanh(c(t))<br><br>\n",
    "where ⊗ represents element-wise multiplication </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gates: \n",
    "\n",
    "+ each gate is essentially its own neuron / perceptron\n",
    "    + input * weight, add a bias, activate!\n",
    "\n",
    "    \n",
    "## Why?\n",
    "\n",
    "+ The gates work together to modulate the Attention Mechanism\n",
    "+ f(t): foget gate / remember vector\n",
    "    + binary decision to drop or retain the input it receives\n",
    "+ i(t): input gate / save vector\n",
    "    + how much of input to allow into the cell state\n",
    "+ o(t): output gate / attention mechanism\n",
    "    + what part of information should the neuron be focusing on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "_ | _ \n",
    ":---:|:---:\n",
    "<img src=\"LSTMcell.pdf\" alt=\"LSTM\" width=\"500\" height=\"500\"/> | <p style=\"text-align: left;\">`i(t)` = σ(W)xi·x(t) +Whi ·h(t−1) +bi <br><br>`f(t)` =σ(W)xf·x(t)+Whf ·h(t−1)+bf <br><br>`o(t)` = σ(W)xo·x(t) +Who ·h(t−1) +bo <br><br>**`g(t)`** = σ(W)xg·x(t) +Whg ·h(t−1) +bg<br><br><br><br>`c(t)` = f(t) ⊗ c(t−1) + i(t) ⊗ g(t) <br><br>`y(t)` = h(t) = o(t) ⊗ tanh(c(t))<br><br> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learn to code an LSTM cell from scratch:\n",
    "\n",
    "## See [Siraj Rival's LSTM YouTube video and the associated links](https://www.youtube.com/watch?v=9zhrxE5PQgY)!\n",
    "\n",
    "## And check out [LSTMVis](http://lstm.seas.harvard.edu) from harvardnlp and Harvard's Visual Computing Group,\n",
    "\n",
    "## As well as Andrej Karpathy's [LSTM blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) The \"What\"\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"Why\" <br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"Why\"\n",
    " | <p style=\"text-align: center;\"> Classical methods </p> | <p style=\"text-align: center;\"> DL/AI </p>\n",
    ":--------:|:----------------:|:--------------:\n",
    "<p style=\"text-align: center;\"> Pre-processing </p> | <p style=\"text-align: left;\"> + Smooth; Remove noise, gravity component, etc. <br> + Use many sensors and channels (e.g., gyroscope, magnetometer) </p> | <p style=\"text-align: left;\">+ Keep to a minimum <br> + Standardize data </p>\n",
    "<p style=\"text-align: center;\"> Feature Extraction </p> | <p style=\"text-align: left;\">+ Generate many hand-crafted features <br> (e.g., 551 for the HAR dataset) </p> | <p style=\"text-align: left;\">+ Let the network do this for you </p>\n",
    "<p style=\"text-align: center;\"> Learning Algorithm </p> | <p style=\"text-align: left;\">+ Many to chose from <br> + Depedent on parameter choice </p> | <p style=\"text-align: left;\">+ Optimize hyperparams <br> + Parameters are learned from the data </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"Why\"\n",
    "### Both Classical and NN/AI methods have been shown to perform well, \n",
    "### But, given the trending goal of online and on-device classification, can we agree that NNs deserve some attention?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"What\"\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) The \"Why\" \n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) The \"How\" <br><br>\n",
    "\n",
    "<p style=\"text-align: center;\"> <img src=\"https://i.ytimg.com/vi/Msk-A99oo10/maxresdefault.jpg\" alt=\"keras\" width=\"500\" height=\"300\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) The \"How\" - Data Processing\n",
    "\n",
    "_ | _\n",
    ":---:|:---:\n",
    " <p style=\"text-align: left;\"> + Sliding window <br><br><br> + Batch size <br><br><br> +Step size </p> | <img src=\"https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/84f7b9d697ad786a6ca6e4170c072b5882803229/13-Figure5-1.png\" alt=\"sliding_wind\" width=\"500\" height=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Using Long Short-Term Memory Recurrent Neural Networks\" </p>\n",
    "###  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) The \"How\" - Hyperparameters, Architectures\n",
    "\n",
    "Category | Hyperparameter \n",
    ":---:|:---:\n",
    "<p style=\"text-align: left;\"> Architecture </p> | <p style=\"text-align: left;\"> Units &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Layers </p>  \n",
    "<p style=\"text-align: left;\"> Forward processing </p>| <p style=\"text-align: left;\"> Activation Function &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Weight Init </p>\n",
    "<p style=\"text-align: left;\"> Regularization</p> | <p style=\"text-align: left;\"> Gradient clipping &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Dropout &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Batch Normalization </p>\n",
    "<p style=\"text-align: left;\"> Learning </p>| <p style=\"text-align: left;\">Optimizers &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Learning Rate </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### <p style=\"text-align: center;\"> ... And now to put it all together ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Developing a Start-to-Finish Pipeline\" </p>\n",
    "####  <p style=\"text-align: center;\"> (for the aforementioned data and models) </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> \"Developing a Start-to-Finish Pipeline\" </p>\n",
    "####  <p style=\"text-align: center;\"> (for the aforementioned data and models) </p>\n",
    "\n",
    "## <p style=\"text-align: center;\"> GOAL 1: UNIFY previous works and STANDARDIZE future work </p>\n",
    "## <p style=\"text-align: center;\"> GOAL 2: Provide POC for optimized Baseline LSTM on _only_ semi-raw trixial accelerometer data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Over 30 studies analyzed  </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a **unique implementation** of LSTMs for HAR using Accelerometer data </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a unique implementation of LSTMs for HAR using Accelerometer data </p>\n",
    "\n",
    "![](http://www.mdpi.com/sensors/sensors-18-00679/article_deploy/html/images/sensors-18-00679-g006.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a unique implementation of LSTMs for HAR using Accelerometer data </p>\n",
    "\n",
    "\n",
    "![](https://image.slidesharecdn.com/javier-171204143541/95/state-of-the-art-timeseries-analysis-with-deep-learning-by-javier-ordez-at-big-data-spain-2017-30-638.jpg?cb=1512399195)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a unique implementation of LSTMs for HAR using Accelerometer data </p>\n",
    "#### <p style=\"text-align: center;\"> Multivariate Fully Convolutional LSTM </p>\n",
    "\n",
    "![](https://www.researchgate.net/profile/Somshubra_Majumdar/publication/322517887/figure/fig1/AS:583263631495168@1516072294208/The-MLSTM-FCN-architecture-LSTM-cells-can-be-replaced-by-Attention-LSTM-cells-to.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a unique implementation of LSTMs for HAR using Accelerometer data </p>\n",
    "\n",
    "![](https://image.slidesharecdn.com/mdrnn-yandexmoscowcv-160427182305/95/multidimensional-rnn-19-638.jpg?cb=1461781453)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a unique implementation of LSTMs for HAR using Accelerometer data </p>\n",
    "#### <p style=\"text-align: center;\"> Deep Residual Bidirectional LSTMs </p>\n",
    "<p style=\"text-align: center;\"> <img src=\"https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/26ebc1b9e21db68d5abf01acd2a0c38d260c65a1/17-Figure5-1.png\" alt=\"drblstm\" width=\"300\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a unique implementation of LSTMs for HAR using Accelerometer data </p>\n",
    "#### <p style=\"text-align: center;\"> Hierarchical LSTMs </p>\n",
    "![](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/8a3afde910fc3ebd95fdb51a157883b81bfc7e73/3-Figure2-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a unique implementation of LSTMs for HAR using Accelerometer data </p>\n",
    "#### <p style=\"text-align: center;\"> Ensemble LSTMs </p>\n",
    "<p style=\"text-align: center;\"> <img src=\"https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/08ce8a8de4d0f7a74fed67373841ee9c458b65b1/9-Figure3-1.png\" alt=\"ensemble_lstm\" width=\"400\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Each used a unique implementation of LSTMs for HAR using Accelerometer data </p>\n",
    "\n",
    "#### <p style=\"text-align: center;\"> Meanwhile, some are still asking, do LSTMs even make sense to use?\n",
    "\n",
    "![](https://ubisafe.org/images/complexities-clipart-confusion-5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### Research into the _functioning_ of LSTMs for classifying accelerometer data is very sparse\n",
    "### This sort of research for LSTMs has mainly been done for text processing\n",
    "\n",
    "<img src=\"http://karpathy.github.io/assets/rnn/pane1.png\" alt=\"Karpathy\" width=\"400\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> Within the LSTM layers, the hyperparameter settings were all across the board\n",
    "\n",
    "+ Many provided little to no justification for there choice\n",
    "+ Those who did test over a range of hyperparameters used small ranges that did not overlap with ranges used by others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> Within the LSTM layers, the hyperparameter settings were all across the board\n",
    "+ Meanwhile, one study used fANOVA to find that certain hyperparameter settings _do_ affect the outcomes\n",
    "+ Many of the settings matched those optimized for text processing, but might they be different for accelerometer-based HAR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> Within the LSTM layers, the hyperparameter settings were all across the board\n",
    "\n",
    " Hyperparam | Range found in Lit\n",
    ":----------:|:-------------:\n",
    "n Layers | 1, 2, 3, 4\n",
    "units per layer | 3 - 512\n",
    "recurrent activation fnxn | sigmoid*\n",
    "cell output activation fnxn | tanh* relu sigmoid softmax linear\n",
    "weight init | random orthogonal, fixed random seed, Glorot uniform, <br>random uniform on [-1, 1], random normal distribution\n",
    "mini batch sizes | 32 - 450\n",
    "loss fnxn | categorical cross entropy, F1 score loss, MSE, MAE\n",
    "optimization | RMSprop, Adam, Adagrad, Nadam, Adadelta\n",
    "learning rate | 1e−7,1e−6,1e−5,1e−4,1e−3,1e−2,1e−1\n",
    "regularization schemes | weight decay, dropout, momentum, <br> gradient clipping, batch normalization \n",
    "epochs | 10-10000 with early stopping\n",
    "sliding winow size | 32 - 5000 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> Within the LSTM layers, the hyperparameter settings were all across the board\n",
    "\n",
    " Hyperparam | Range found in Lit\n",
    ":----------:|:-------------:\n",
    "n Layers | 1, 2, 3, 4\n",
    "units per layer | 3 - 512\n",
    "recurrent activation fnxn | sigmoid*\n",
    "cell output activation fnxn | tanh* relu sigmoid softmax linear\n",
    "weight init | random orthogonal, fixed random seed, Glorot uniform, <br>random uniform on [-1, 1], random normal distribution\n",
    "mini batch sizes | 32 - 450\n",
    "loss fnxn | categorical cross entropy, F1 score loss, MSE, MAE\n",
    "optimization | RMSprop, Adam, Adagrad, Nadam, Adadelta\n",
    "learning rate | 1e−7,1e−6,1e−5,1e−4,1e−3,1e−2,1e−1\n",
    "regularization schemes | weight decay, dropout, momentum, <br> gradient clipping, batch normalization \n",
    "epochs | 10-10000 with early stopping\n",
    "sliding winow size | 32 - 5000 ms\n",
    "\n",
    "**Even if we discretize each of these Hyperparameters into, e.g., 5 options per hyperparameter, that's still 5^11 = tens of millions of possible combinations** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> Within the LSTM layers, the hyperparameter settings were all across the board\n",
    "\n",
    "+ **Even if we discretize each of these Hyperparameters into, e.g., 5 options per hyperparameter, that's still 5^11 = tens of millions of possible combinations** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unifying the Field with Bayesian Optimization \n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1200/1*06Pxt_qLpS4gKFV373FdNQ.png)\n",
    "\n",
    "## <p style=\"text-align: right;\"> More on this later... </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> All kinds of preprocessing methods were used\n",
    "\n",
    "+ Nadaraya-Watson kernel weighted avg with Epanachnikov quadratic kernel and 40 nearest-neight window size\n",
    "+ remove gravity acceleration by applying median filter of length 2sec to each dimension and subratcting result \n",
    "+ construct movement borders (re hand orientation) via derivative of previously extracted gravity signals and calculating vector magnitude) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> And many used additional data \n",
    "\n",
    "Gyroscope | Magnetometer\n",
    ":--------:|:------------:\n",
    "![](http://4.bp.blogspot.com/-23gT2U3Pf1Y/TeRamaf53zI/AAAAAAAAAdo/7QF2gArigXw/s1600/Gyroscope.jpg) | ![](https://howtomechatronics.com/wp-content/uploads/2015/11/Magnetometer-How-It-Works-Hall-Effect-.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But wouldn't it be neat if we could just use triaxial accelerometer data?\n",
    "\n",
    "### Less data to store, transfer, process...\n",
    "### Puts the burden on the model !\n",
    "## <p style=\"text-align: right;\"> More on this later... </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> HAZARD: Data Leakage </p>\n",
    "\n",
    "<img src=\"https://blog.rootshell.be/wp-content/uploads/2010/01/data-leakage.jpg\" alt=\"data_leakage\" width=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://chrisalbon.com/images/machine_learning_flashcards/Standardization_print.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://cdn-images-1.medium.com/max/1200/1*4G__SV580CxFj78o9yUXuQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Breakdown of Related Works:\n",
    "\n",
    "### <p style=\"text-align: center;\"> Results: The Strong vs. The Weak </p>\n",
    "\n",
    "CV, Repeated Experiments &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ... vs. ... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Single Best Result\n",
    "<img src=\"https://previews.123rf.com/images/jehsomwang/jehsomwang1705/jehsomwang170500029/77712286-opposite-words-strong-and-weak-vector-illustration.jpg\" alt=\"strongweak\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Methods </p>\n",
    "\n",
    "<p style=\"text-align: center;\"> <img src=\"https://i.ytimg.com/vi/Msk-A99oo10/maxresdefault.jpg\" alt=\"keras\" width=\"500\" height=\"300\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The data ...\n",
    "\n",
    "+ UCI HAR Dataset\n",
    "    + Used only the triaxial accelerometer data\n",
    "    + 30 volunteers\n",
    "    + Each performed 6 motor activities \n",
    "        + Walking, Upstairs, Downstairs, Sittinng, Standing, Layinng\n",
    "        + Recorded in a single time series with ~650,000 time steps\n",
    "    + Accelerometer: embedded accelerometer in iPhone, worn on hip\n",
    "    + https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First off, let's fix this formatting ... \n",
    "\n",
    "+ The data is provided pre-windowed and pre-split into test/train sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First off, let's fix this formatting ... \n",
    "\n",
    "<img src=\"HAR.png\" alt=\"HAR\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now let's optimize this network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now let's optimize this network\n",
    "\n",
    "+ With millions of possible hyperparameter configurations, grid search with packages like `GridSearchCV` from `scikit-learn` won't do ... \n",
    "+ We need some **heuristics** to help speed the search!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modeling the search space (i.e., data science)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/MultivariateNormal.png/300px-MultivariateNormal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now let's optimize this network\n",
    "\n",
    "### <p style=\"text-align: center;\"> Tree-Structured Parzen Estimators, implemented via `Hyperas` from `Hyperopt` </p>\n",
    "\n",
    "#### <p style=\"text-align: center;\"> An Expected Improvement algorithm </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tree-Structured Parzen Estimators\n",
    "![](https://image.slidesharecdn.com/pydatahyperparameter-180720220712/95/towards-automating-machine-learning-benchmarking-tools-for-hyperparameter-tuning-dr-thorben-jensen-12-638.jpg?cb=1532124486)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now let's optimize this network\n",
    "\n",
    "### <p style=\"text-align: center;\"> Tree-Structured Parzen Estimators, implemented via `Hyperas` from `Hyperopt` </p>\n",
    "\n",
    "#### <p style=\"text-align: center;\"> An Expected Improvement algorithm </p>\n",
    "\n",
    "<img src=\"TPE.png\" alt=\"TPE\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now that we've prepared our data and optimized our network, let's throw it all into a reproducible Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now that we've prepared our data and optimized our network, let's throw it all into a reproducible Pipeline\n",
    "\n",
    "<img src=\"Pipeline.png\" alt=\"HAR\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A Note on Performance Measures: Don't be fooled by the Accuracy Paradox!\n",
    "\n",
    "+ Multiclass predictions: \n",
    "    + Each class has its TP, TN, FP, FN\n",
    "+ Micro- vs. Macro- performance measures\n",
    "    + Macro- computes the PM for each class and averages\n",
    "    + Micro- aggregates the stats from each class and then computes a single PM (accounts for class imbalance!)\n",
    "    \n",
    "+ **F1 Score** takes into account **Recall** and **Precision**\n",
    "    + i.e., how many of the relevant items did we predict, and how many of the items we predicted were relevant, respectively \n",
    "    + more robust than accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results: \n",
    "\n",
    "![](Results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <p style=\"text-align: center;\"> Key Takeaways: </p>\n",
    "\n",
    "+ LSTM's have great potential for online on-device Human Activity Recognition from raw accelerometer data alone  \n",
    "+ We still have a lot to learn about LSTM cells' specific functioning when processing accelerometer data\n",
    "+ As such, case-wise model optimization is important! \n",
    "+ Additionally, we should be reporting the parameters we use, the ranges we test over, our reasoning and justifications thereof \n",
    "+ CV yields robust results; micro-F1 Score is more robust than Accuracy\n",
    "+ Pipelines allow reproducibility\n",
    "\n",
    "The code: https://github.com/xtianmcd/accelstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
